{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Imported to enable the use of datastructures like dataframe\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train='Original Datasets/malayalam_train.tsv'\n",
    "path_test='Original Datasets/malayalam_test.tsv'\n",
    "path_val='Original Datasets/malayalam_dev.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path_train, sep='\\t')\n",
    "# print(df_train)\n",
    "\n",
    "df_val = pd.read_csv(path_val, sep='\\t')\n",
    "# print(df_val)\n",
    "\n",
    "df_test = pd.read_csv(path_test, sep='\\t')\n",
    "# print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4851, 2)\n",
      "(1348, 3)\n",
      "(540, 2)\n",
      "Total =  6739\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_val.shape)\n",
    "\n",
    "total=df_val.shape[0]+df_test.shape[0]+df_train.shape[0]\n",
    "print(\"Total = \",total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6739, 3)\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     df_test = df_test.drop('id', axis=1)\n",
    "# except:\n",
    "#     print(\"already dropped column\")\n",
    "\n",
    "df_dataset = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
    "print(df_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Positive          2811\n",
      "Neutral           1903\n",
      "Not-Malayalam      884\n",
      "Negative           738\n",
      "Mixed_feelings     403\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Renaming (df_train) the classes for convenience\n",
    "\n",
    "# Removing any leading/trailing spaces\n",
    "df_dataset['category'] = df_dataset['category'].str.strip()\n",
    "\n",
    "# Replacing 'unknown_state' with 'Irrelevant'\n",
    "df_dataset['category'] = df_dataset['category'].replace({'unknown_state': 'Neutral'})\n",
    "df_dataset['category'] = df_dataset['category'].replace({'not-malayalam': 'Not-Malayalam'})\n",
    "\n",
    "# Viewing the number of items in each class after replacement\n",
    "print(df_dataset['category'].value_counts())  # Used to view the number of items in each class.\n",
    "\n",
    "## There is a significant imbalance in the classes in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Positive          2022\n",
      "Neutral           1344\n",
      "Not-Malayalam      647\n",
      "Negative           549\n",
      "Mixed_feelings     289\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Renaming (df_train) the classes for convenience\n",
    "\n",
    "# Removing any leading/trailing spaces\n",
    "df_train['category'] = df_train['category'].str.strip()\n",
    "\n",
    "# Replacing 'unknown_state' with 'Irrelevant'\n",
    "df_train['category'] = df_train['category'].replace({'unknown_state': 'Neutral'})\n",
    "df_train['category'] = df_train['category'].replace({'not-malayalam': 'Not-Malayalam'})\n",
    "\n",
    "# Viewing the number of items in each class after replacement\n",
    "print(df_train['category'].value_counts())  # Used to view the number of items in each class.\n",
    "\n",
    "## There is a significant imbalance in the classes in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Positive          565\n",
      "Neutral           398\n",
      "Not-Malayalam     177\n",
      "Negative          138\n",
      "Mixed_feelings     70\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Renaming (df_test) the classes for convenience\n",
    "\n",
    "# Removing any leading/trailing spaces\n",
    "df_test['category'] = df_test['category'].str.strip()\n",
    "\n",
    "# Replacing 'unknown_state' with 'Irrelevant'\n",
    "df_test['category'] = df_test['category'].replace({'unknown_state': 'Neutral'})\n",
    "df_test['category'] = df_test['category'].replace({'not-malayalam': 'Not-Malayalam'})\n",
    "\n",
    "# Viewing the number of items in each class after replacement\n",
    "print(df_test['category'].value_counts())  # Used to view the number of items in each class.\n",
    "\n",
    "## There is a significant imbalance in the classes in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Positive          224\n",
      "Neutral           161\n",
      "Not-Malayalam      60\n",
      "Negative           51\n",
      "Mixed_feelings     44\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Renaming (df_val) the classes for convenience\n",
    "\n",
    "# Removing any leading/trailing spaces\n",
    "df_val['category'] = df_val['category'].str.strip()\n",
    "\n",
    "# Replacing 'unknown_state' with 'Irrelevant'\n",
    "df_val['category'] = df_val['category'].replace({'unknown_state': 'Neutral'})\n",
    "df_val['category'] = df_val['category'].replace({'not-malayalam': 'Not-Malayalam'})\n",
    "\n",
    "# Viewing the number of items in each class after replacement\n",
    "print(df_val['category'].value_counts())  # Used to view the number of items in each class.\n",
    "\n",
    "## There is a significant imbalance in the classes in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(565, 3)\n",
      "(138, 3)\n",
      "(70, 3)\n",
      "(0, 3)\n",
      "(0, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframes for (df_train) all categories for later use\n",
    "\n",
    "df_dataset_positive_words = df_dataset[df_dataset['category']=='Positive']\n",
    "df_dataset_negative_words = df_dataset[df_dataset['category']=='Negative']\n",
    "df_dataset_mixed_feeling_words = df_dataset[df_dataset['category']=='Mixed_feelings']\n",
    "df_dataset_neutral_words = df_dataset[df_dataset['category']=='Neutral']\n",
    "df_dataset_not_malayalam_words = df_dataset[df_dataset['category']=='Not-Malayalam']\n",
    "\n",
    "print(df_dataset_positive_words.shape)\n",
    "print(df_dataset_negative_words.shape)\n",
    "print(df_dataset_mixed_feeling_words.shape)\n",
    "print(df_dataset_neutral_words.shape)\n",
    "print(df_dataset_not_malayalam_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2022, 2)\n",
      "(549, 2)\n",
      "(289, 2)\n",
      "(1344, 2)\n",
      "(647, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframes for (df_train) all categories for later use\n",
    "\n",
    "df_train_positive_words = df_train[df_train['category']=='Positive']\n",
    "df_train_negative_words = df_train[df_train['category']=='Negative']\n",
    "df_train_mixed_feeling_words = df_train[df_train['category']=='Mixed_feelings']\n",
    "df_train_neutral_words = df_train[df_train['category']=='Neutral']\n",
    "df_train_not_malayalam_words = df_train[df_train['category']=='Not-Malayalam']\n",
    "\n",
    "print(df_train_positive_words.shape)\n",
    "print(df_train_negative_words.shape)\n",
    "print(df_train_mixed_feeling_words.shape)\n",
    "print(df_train_neutral_words.shape)\n",
    "print(df_train_not_malayalam_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(565, 3)\n",
      "(138, 3)\n",
      "(70, 3)\n",
      "(398, 3)\n",
      "(177, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframes for (df_test) all categories for later use\n",
    "\n",
    "df_test_positive_words = df_test[df_test['category']=='Positive']\n",
    "df_test_negative_words = df_test[df_test['category']=='Negative']\n",
    "df_test_mixed_feeling_words = df_test[df_test['category']=='Mixed_feelings']\n",
    "df_test_neutral_words = df_test[df_test['category']=='Neutral']\n",
    "df_test_not_malayalam_words = df_test[df_test['category']=='Not-Malayalam']\n",
    "\n",
    "print(df_test_positive_words.shape)\n",
    "print(df_test_negative_words.shape)\n",
    "print(df_test_mixed_feeling_words.shape)\n",
    "print(df_test_neutral_words.shape)\n",
    "print(df_test_not_malayalam_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 2)\n",
      "(51, 2)\n",
      "(44, 2)\n",
      "(161, 2)\n",
      "(60, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframes for (df_val) all categories for later use\n",
    "\n",
    "df_val_positive_words = df_val[df_val['category']=='Positive']\n",
    "df_val_negative_words = df_val[df_val['category']=='Negative']\n",
    "df_val_mixed_feeling_words = df_val[df_val['category']=='Mixed_feelings']\n",
    "df_val_neutral_words = df_val[df_val['category']=='Neutral']\n",
    "df_val_not_malayalam_words = df_val[df_val['category']=='Not-Malayalam']\n",
    "\n",
    "print(df_val_positive_words.shape)\n",
    "print(df_val_negative_words.shape)\n",
    "print(df_val_mixed_feeling_words.shape)\n",
    "print(df_val_neutral_words.shape)\n",
    "print(df_val_not_malayalam_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510 comments have more than 15 words\n",
      "301 comments have less than 5 words\n",
      "309 sentences have emojis in them\n",
      "1120 sentences were not preprocessed\n",
      "6739\n"
     ]
    }
   ],
   "source": [
    "# Pre processing is not done as mentioned in the paper.\n",
    "\n",
    "# We preprocessed the comments by removing the emoji’s,\n",
    "# and sentence length longer than 15 or less than 5 words since\n",
    "# sentence more than 15 words will be difficult for annotators.\n",
    "# After cleaning, we got 6,738 sentences for Malayalam-English\n",
    "# code-mixed post comments.\n",
    "\n",
    "# Function to count words in a sentence\n",
    "def count_words(sentence):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    # Count the words\n",
    "    word_count = len(words)\n",
    "    return word_count\n",
    "\n",
    "# Apply the function and filter the DataFrame\n",
    "df_wordsGreater15 = df_dataset[df_dataset['text'].apply(lambda x: count_words(x) > 15)]\n",
    "df_wordsLess5 = df_dataset[df_dataset['text'].apply(lambda x: count_words(x) < 5)]\n",
    "\n",
    "\n",
    "# Function to check if a sentence contains any emoji\n",
    "def contains_emoji(sentence):\n",
    "    for character in sentence:\n",
    "        if emoji.is_emoji(character):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the function and count sentences with emojis\n",
    "df_emojis = df_dataset[df_dataset['text'].apply(contains_emoji)]\n",
    "\n",
    "print(str(df_wordsGreater15.shape[0]) + \" comments have more than 15 words\") #236 sentences have more than 15 words\n",
    "print(str(df_wordsLess5.shape[0]) + \" comments have less than 5 words\") #346 sentences have less than 5 words\n",
    "print(str(df_emojis.shape[0]) + \" sentences have emojis in them\") #309 sentences have emojis in them\n",
    "print(str(df_wordsGreater15.shape[0]+df_wordsLess5.shape[0]+df_emojis.shape[0]) + \" sentences were not preprocessed\")\n",
    "print(str(df_dataset.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing emojis\n",
    "\n",
    "# Function to remove emojis from a string\n",
    "def remove_emojis(text):\n",
    "    # Using emoji.get_emoji_regexp() to match all emojis in the text\n",
    "    # and replace them with an empty string\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "# Apply the function to remove emojis from the 'text' column\n",
    "df_dataset['text'] = df_dataset['text'].apply(remove_emojis)\n",
    "\n",
    "df_val['text'] = df_val['text'].apply(remove_emojis)\n",
    "df_test['text'] = df_test ['text'].apply(remove_emojis)\n",
    "df_train['text'] = df_train['text'].apply(remove_emojis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing sentences with more than 15 words and less than 5 words\n",
    "df_dataset = df_dataset[~df_dataset['text'].isin(df_wordsGreater15['text'])]\n",
    "df_dataset = df_dataset[~df_dataset['text'].isin(df_wordsLess5['text'])]\n",
    "\n",
    "# Apply the function and filter the DataFrame\n",
    "df_val_wordsGreater15 = df_val[df_val['text'].apply(lambda x: count_words(x) > 15)]\n",
    "df_val_wordsLess5 = df_val[df_val['text'].apply(lambda x: count_words(x) < 5)]\n",
    "\n",
    "#val\n",
    "df_val = df_val[~df_val['text'].isin(df_val_wordsGreater15['text'])]\n",
    "df_val = df_val[~df_val['text'].isin(df_val_wordsLess5['text'])]\n",
    "\n",
    "# Apply the function and filter the DataFrame\n",
    "df_test_wordsGreater15 = df_test[df_test['text'].apply(lambda x: count_words(x) > 15)]\n",
    "df_test_wordsLess5 = df_test[df_test['text'].apply(lambda x: count_words(x) < 5)]\n",
    "\n",
    "#test\n",
    "df_test = df_test[~df_test['text'].isin(df_test_wordsGreater15['text'])]\n",
    "df_test = df_test[~df_test['text'].isin(df_test_wordsLess5['text'])]\n",
    "\n",
    "# Apply the function and filter the DataFrame\n",
    "df_train_wordsGreater15 = df_train[df_train['text'].apply(lambda x: count_words(x) > 15)]\n",
    "df_train_wordsLess5 = df_train[df_train['text'].apply(lambda x: count_words(x) < 5)]\n",
    "\n",
    "#train\n",
    "df_train = df_train[~df_train['text'].isin(df_train_wordsGreater15['text'])]\n",
    "df_train = df_train[~df_train['text'].isin(df_train_wordsLess5['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1181, 3)\n",
      "(4283, 2)\n",
      "(463, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_excel(f'Preprocessed_Original_Train_Data.xlsx', index=False)\n",
    "df_val.to_excel(f'Preprocessed_Original_Val_Data.xlsx', index=False)\n",
    "df_test.to_excel(f'Preprocessed_Original_Test_Data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
